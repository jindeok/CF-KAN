{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import scipy.sparse as sp\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import ndcg_score\n",
    "import numpy as np\n",
    "import os\n",
    "from utils import csr2torch, recall_at_k, ndcg_at_k\n",
    "import math \n",
    "import random\n",
    "from models import *\n",
    "\n",
    "random.seed(2022)\n",
    "np.random.seed(2022)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/Desktop/jinduk/KAN_REC/utils.py:65: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /opt/conda/conda-bld/pytorch_1695392022560/work/torch/csrc/utils/tensor_new.cpp:261.)\n",
      "  torch.LongTensor([coo.row, coo.col]),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of users: 5949\n",
      "number of items: 2810\n",
      "Epoch 1/10, Loss: 1793.2622\n",
      "Epoch 2/10, Loss: 318.6188\n",
      "Epoch 3/10, Loss: 171.7812\n",
      "Epoch 4/10, Loss: 151.0540\n",
      "Epoch 5/10, Loss: 144.9136\n",
      "Epoch 6/10, Loss: 141.7007\n",
      "Epoch 7/10, Loss: 139.8040\n",
      "Epoch 8/10, Loss: 138.9353\n",
      "Epoch 9/10, Loss: 138.7164\n",
      "Epoch 10/10, Loss: 138.9347\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "\n",
    "# Define KAN-based Autoencoder\n",
    "class KANAutoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dims, grid_size=5, spline_order=3):\n",
    "        super(KANAutoencoder, self).__init__()\n",
    "        self.encoder = KAN([input_dim] + hidden_dims, grid_size, spline_order)\n",
    "        self.decoder = KAN(hidden_dims[::-1] + [input_dim], grid_size, spline_order)\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "    def regularization_loss(self, regularize_activation=1.0, regularize_entropy=1.0):\n",
    "        return self.encoder.regularization_loss(regularize_activation, regularize_entropy) + \\\n",
    "               self.decoder.regularization_loss(regularize_activation, regularize_entropy)\n",
    "\n",
    "\n",
    "\n",
    "# Training parameters\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "epochs = 10\n",
    "batch_size = 256\n",
    "learning_rate = 0.001\n",
    "hidden_dims = [128, 64, 32]\n",
    "verbose = 1\n",
    "\n",
    "# Load dataset\n",
    "dataset = \"ml-1m\"\n",
    "path_tr = f\"{current_directory}/dataset/{dataset}_train.npz\"\n",
    "path_ts = f\"{current_directory}/dataset/{dataset}_test.npz\"\n",
    "R_tr = csr2torch(sp.load_npz(path_tr)).to(device)\n",
    "R_ts = csr2torch(sp.load_npz(path_ts)).to(device)\n",
    "\n",
    "n_users = R_tr.shape[0]\n",
    "n_items = R_tr.shape[1]\n",
    "if verbose:\n",
    "    print(f\"number of users: {n_users}\")\n",
    "    print(f\"number of items: {n_items}\")\n",
    "\n",
    "# Create DataLoader\n",
    "train_dataset = TensorDataset(R_tr)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Initialize model, optimizer, and loss function\n",
    "model = KANAutoencoder(n_items, hidden_dims).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for batch in train_loader:\n",
    "        inputs = batch[0].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, inputs) + model.regularization_loss()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    if verbose:\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {train_loss:.4f}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@10: 0.2013\n",
      "NDCG@10: 0.1315\n"
     ]
    }
   ],
   "source": [
    "# Evaluation metrics\n",
    "def recall_at_k(predictions, targets, k):\n",
    "    top_k_preds = torch.topk(predictions, k=k, dim=1).indices\n",
    "    hits = torch.sum(torch.gather(targets, 1, top_k_preds), dim=1)\n",
    "    return torch.mean(hits.float() / torch.clamp(torch.sum(targets, dim=1).float(), max=k))\n",
    "\n",
    "def ndcg_at_k(predictions, targets, k):\n",
    "    top_k_preds = torch.topk(predictions, k=k, dim=1).indices\n",
    "    gains = torch.gather(targets, 1, top_k_preds)\n",
    "    discounts = torch.log2(torch.arange(2, k + 2, device=targets.device).float())\n",
    "    dcg = torch.sum(gains / discounts, dim=1)\n",
    "    idcg = torch.sum(torch.sort(targets, descending=True, dim=1).values[:, :k] / discounts, dim=1)\n",
    "    return torch.mean(dcg / idcg)\n",
    "\n",
    "# Evaluate on test set using CPU (to prevent GPU O.O.M)\n",
    "def evaluate_model(model, test_data, batch_size=64):\n",
    "    model.eval()\n",
    "    model.to('cpu')\n",
    "    test_data = test_data.to('cpu')\n",
    "\n",
    "    num_samples = test_data.size(0)\n",
    "    all_predictions = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(0, num_samples, batch_size):\n",
    "            batch_data = train_data[i:i + batch_size]\n",
    "            batch_predictions = model(batch_data)\n",
    "            all_predictions.append(batch_predictions)\n",
    "\n",
    "    all_predictions = torch.cat(all_predictions, dim=0)\n",
    "    recall = recall_at_k(all_predictions, test_data, k=20).item()\n",
    "    ndcg = ndcg_at_k(all_predictions, test_data, k=20).item()\n",
    "\n",
    "    return recall, ndcg\n",
    "\n",
    "# Using the evaluate_model function\n",
    "recall, ndcg = evaluate_model(model, R_ts, batch_size=64)\n",
    "\n",
    "if verbose:\n",
    "    print(f\"Recall@20: {recall:.4f}\")\n",
    "    print(f\"NDCG@20: {ndcg:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA memory allocated: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mallocated_memory\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m MB\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA memory reserved: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreserved_memory\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m MB\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m \u001b[43mprint_cuda_memory_usage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m, in \u001b[0;36mprint_cuda_memory_usage\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprint_cuda_memory_usage\u001b[39m():\n\u001b[0;32m----> 2\u001b[0m     allocated_memory \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mmemory_allocated() \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m1024\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[1;32m      3\u001b[0m     reserved_memory \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mmemory_reserved() \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m1024\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA memory allocated: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mallocated_memory\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m MB\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "def print_cuda_memory_usage():\n",
    "    allocated_memory = torch.cuda.memory_allocated() / 1024**2\n",
    "    reserved_memory = torch.cuda.memory_reserved() / 1024**2\n",
    "    print(f\"CUDA memory allocated: {allocated_memory:.2f} MB\")\n",
    "    print(f\"CUDA memory reserved: {reserved_memory:.2f} MB\")\n",
    "print_cuda_memory_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
